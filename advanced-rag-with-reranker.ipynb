{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":" %%capture\n! pip install -q --upgrade llama-index pypdf llama-index llama-index-embeddings-huggingface sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-21T06:39:22.066875Z","iopub.execute_input":"2024-06-21T06:39:22.067534Z","iopub.status.idle":"2024-06-21T06:39:43.924644Z","shell.execute_reply.started":"2024-06-21T06:39:22.067500Z","shell.execute_reply":"2024-06-21T06:39:43.923237Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install llama-index-llms-llama-cpp\n!pip install llama-index-vector-stores-chroma","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:39:43.927130Z","iopub.execute_input":"2024-06-21T06:39:43.927844Z","iopub.status.idle":"2024-06-21T06:42:03.467805Z","shell.execute_reply.started":"2024-06-21T06:39:43.927800Z","shell.execute_reply":"2024-06-21T06:42:03.466580Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## get the data\n!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:42:03.469134Z","iopub.execute_input":"2024-06-21T06:42:03.469424Z","iopub.status.idle":"2024-06-21T06:42:06.256814Z","shell.execute_reply.started":"2024-06-21T06:42:03.469397Z","shell.execute_reply":"2024-06-21T06:42:06.255630Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2024-06-21 06:42:04--  https://openreview.net/pdf?id=VtmBAGCN7o\nResolving openreview.net (openreview.net)... 35.184.86.251\nConnecting to openreview.net (openreview.net)|35.184.86.251|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 16911937 (16M) [application/pdf]\nSaving to: 'metagpt.pdf'\n\nmetagpt.pdf         100%[===================>]  16.13M  14.2MB/s    in 1.1s    \n\n2024-06-21 06:42:06 (14.2 MB/s) - 'metagpt.pdf' saved [16911937/16911937]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_index.core.settings import Settings\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.llama_cpp import LlamaCPP\nfrom llama_index.core.node_parser import SentenceSplitter\nfrom llama_index.core import VectorStoreIndex, StorageContext\nfrom llama_index.core import SimpleDirectoryReader","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:42:06.258820Z","iopub.execute_input":"2024-06-21T06:42:06.259149Z","iopub.status.idle":"2024-06-21T06:42:26.531949Z","shell.execute_reply.started":"2024-06-21T06:42:06.259119Z","shell.execute_reply":"2024-06-21T06:42:26.530963Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-06-21 06:42:17.449336: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-21 06:42:17.449434: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-21 06:42:17.584363: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"llm  = LlamaCPP(\n   model_url='https://huggingface.co/bartowski/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/Llama-3-8B-Instruct-Gradient-1048k-Q5_K_S.gguf',\n   model_path=None,\n   temperature=0.1,\n   max_new_tokens=256,\n   context_window=3900,\n   generate_kwargs={},\n   model_kwargs={\"n_gpu_layers\":-1},\n   verbose=True\n)\nSettings.llm = llm\nSettings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n\ndocuments = SimpleDirectoryReader(input_files=['/kaggle/working/metagpt.pdf']).load_data()","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:42:26.533374Z","iopub.execute_input":"2024-06-21T06:42:26.534164Z","iopub.status.idle":"2024-06-21T06:44:53.093119Z","shell.execute_reply.started":"2024-06-21T06:42:26.534136Z","shell.execute_reply":"2024-06-21T06:44:53.092266Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading url https://huggingface.co/bartowski/Llama-3-8B-Instruct-Gradient-1048k-GGUF/resolve/main/Llama-3-8B-Instruct-Gradient-1048k-Q5_K_S.gguf to path /tmp/llama_index/models/Llama-3-8B-Instruct-Gradient-1048k-Q5_K_S.gguf\ntotal size (MB): 5599.29\n","output_type":"stream"},{"name":"stderr","text":"5340it [02:18, 38.64it/s]                          \nllama_model_loader: loaded meta data with 26 key-value pairs and 291 tensors from /tmp/llama_index/models/Llama-3-8B-Instruct-Gradient-1048k-Q5_K_S.gguf (version GGUF V3 (latest))\nllama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\nllama_model_loader: - kv   0:                       general.architecture str              = llama\nllama_model_loader: - kv   1:                               general.name str              = Llama-3-8B-Instruct-Gradient-1048k\nllama_model_loader: - kv   2:                          llama.block_count u32              = 32\nllama_model_loader: - kv   3:                       llama.context_length u32              = 1048576\nllama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\nllama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\nllama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\nllama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\nllama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 2804339712.000000\nllama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\nllama_model_loader: - kv  10:                          general.file_type u32              = 16\nllama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\nllama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\nllama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\nllama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\nllama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\nllama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\nllama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\nllama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\nllama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\nllama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\nllama_model_loader: - kv  21:               general.quantization_version u32              = 2\nllama_model_loader: - kv  22:                      quantize.imatrix.file str              = /models/Llama-3-8B-Instruct-Gradient-...\nllama_model_loader: - kv  23:                   quantize.imatrix.dataset str              = /training_data/groups_merged.txt\nllama_model_loader: - kv  24:             quantize.imatrix.entries_count i32              = 224\nllama_model_loader: - kv  25:              quantize.imatrix.chunks_count i32              = 88\nllama_model_loader: - type  f32:   65 tensors\nllama_model_loader: - type q5_K:  225 tensors\nllama_model_loader: - type q6_K:    1 tensors\nllm_load_vocab: special tokens cache size = 256\nllm_load_vocab: token to piece cache size = 0.8000 MB\nllm_load_print_meta: format           = GGUF V3 (latest)\nllm_load_print_meta: arch             = llama\nllm_load_print_meta: vocab type       = BPE\nllm_load_print_meta: n_vocab          = 128256\nllm_load_print_meta: n_merges         = 280147\nllm_load_print_meta: n_ctx_train      = 1048576\nllm_load_print_meta: n_embd           = 4096\nllm_load_print_meta: n_head           = 32\nllm_load_print_meta: n_head_kv        = 8\nllm_load_print_meta: n_layer          = 32\nllm_load_print_meta: n_rot            = 128\nllm_load_print_meta: n_embd_head_k    = 128\nllm_load_print_meta: n_embd_head_v    = 128\nllm_load_print_meta: n_gqa            = 4\nllm_load_print_meta: n_embd_k_gqa     = 1024\nllm_load_print_meta: n_embd_v_gqa     = 1024\nllm_load_print_meta: f_norm_eps       = 0.0e+00\nllm_load_print_meta: f_norm_rms_eps   = 1.0e-05\nllm_load_print_meta: f_clamp_kqv      = 0.0e+00\nllm_load_print_meta: f_max_alibi_bias = 0.0e+00\nllm_load_print_meta: f_logit_scale    = 0.0e+00\nllm_load_print_meta: n_ff             = 14336\nllm_load_print_meta: n_expert         = 0\nllm_load_print_meta: n_expert_used    = 0\nllm_load_print_meta: causal attn      = 1\nllm_load_print_meta: pooling type     = 0\nllm_load_print_meta: rope type        = 0\nllm_load_print_meta: rope scaling     = linear\nllm_load_print_meta: freq_base_train  = 2804339712.0\nllm_load_print_meta: freq_scale_train = 1\nllm_load_print_meta: n_ctx_orig_yarn  = 1048576\nllm_load_print_meta: rope_finetuned   = unknown\nllm_load_print_meta: ssm_d_conv       = 0\nllm_load_print_meta: ssm_d_inner      = 0\nllm_load_print_meta: ssm_d_state      = 0\nllm_load_print_meta: ssm_dt_rank      = 0\nllm_load_print_meta: model type       = 8B\nllm_load_print_meta: model ftype      = Q5_K - Small\nllm_load_print_meta: model params     = 8.03 B\nllm_load_print_meta: model size       = 5.21 GiB (5.57 BPW) \nllm_load_print_meta: general.name     = Llama-3-8B-Instruct-Gradient-1048k\nllm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\nllm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\nllm_load_print_meta: LF token         = 128 'Ä'\nllm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\nllm_load_tensors: ggml ctx size =    0.15 MiB\nllm_load_tensors:        CPU buffer size =  5332.43 MiB\n........................................................................................\nllama_new_context_with_model: n_ctx      = 3904\nllama_new_context_with_model: n_batch    = 512\nllama_new_context_with_model: n_ubatch   = 512\nllama_new_context_with_model: flash_attn = 0\nllama_new_context_with_model: freq_base  = 2804339712.0\nllama_new_context_with_model: freq_scale = 1\nllama_kv_cache_init:        CPU KV buffer size =   488.00 MiB\nllama_new_context_with_model: KV self size  =  488.00 MiB, K (f16):  244.00 MiB, V (f16):  244.00 MiB\nllama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\nllama_new_context_with_model:        CPU compute buffer size =   283.63 MiB\nllama_new_context_with_model: graph nodes  = 1030\nllama_new_context_with_model: graph splits = 1\nAVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \nModel metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_data/groups_merged.txt', 'quantize.imatrix.chunks_count': '88', 'quantize.imatrix.file': '/models/Llama-3-8B-Instruct-Gradient-1048k-GGUF/Llama-3-8B-Instruct-Gradient-1048k.imatrix', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '2804339712.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '1048576', 'general.name': 'Llama-3-8B-Instruct-Gradient-1048k', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '16', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\nAvailable chat formats from metadata: chat_template.default\nGuessed chat format: llama-3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"844a8c2635de4ad981e8a84aa280670f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e34523fbbb4ecba3706608dc69e965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55c60cbefbad46c4a8533bf0c6c89f2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932dedfcd0f74d25a4372b6eea111fcd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16c661a4a868453892220c1041efa80d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"325fe1ddd2c64de390f1097c5b8ad47e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564e1801bb604fb990ec12c0e65f97db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"908f1149b385409c8260a7e48387db30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e446f358d424311b1de9e3da9056919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57327eaff40b4248a4e6b5a798b848f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a6b86405ea4b20b2a79a6dca234310"}},"metadata":{}}]},{"cell_type":"code","source":"print((documents[0].text))","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:44:56.177313Z","iopub.execute_input":"2024-06-21T06:44:56.178149Z","iopub.status.idle":"2024-06-21T06:44:56.182792Z","shell.execute_reply.started":"2024-06-21T06:44:56.178115Z","shell.execute_reply":"2024-06-21T06:44:56.181847Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Preprint\nMETAGPT: M ETA PROGRAMMING FOR A\nMULTI -AGENT COLLABORATIVE FRAMEWORK\nSirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\nCeyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\nLiyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n5Nanjing University,6University of Pennsylvania,\n7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\nABSTRACT\nRemarkable progress has been made on automated problem solving through so-\ncieties of agents based on large language models (LLMs). Existing LLM-based\nmulti-agent systems can already solve simple dialogue tasks. Solutions to more\ncomplex tasks, however, are complicated through logic inconsistencies due to\ncascading hallucinations caused by naively chaining LLMs. Here we introduce\nMetaGPT, an innovative meta-programming framework incorporating efficient\nhuman workflows into LLM-based multi-agent collaborations. MetaGPT en-\ncodes Standardized Operating Procedures (SOPs) into prompt sequences for more\nstreamlined workflows, thus allowing agents with human-like domain expertise\nto verify intermediate results and reduce errors. MetaGPT utilizes an assembly\nline paradigm to assign diverse roles to various agents, efficiently breaking down\ncomplex tasks into subtasks involving many agents working together. On col-\nlaborative software engineering benchmarks, MetaGPT generates more coherent\nsolutions than previous chat-based multi-agent systems. Our project can be found\nat https://github.com/geekan/MetaGPT.\n1 I NTRODUCTION\nAutonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\nhance and replicate human workflows. In real-world applications, however, existing systems (Park\net al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\nLiang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\neffective, coherent, and accurate problem-solving processes, particularly when there is a need for\nmeaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\net al., 2023; Qian et al., 2023).\nThrough extensive collaborative practice, humans have developed widely accepted Standardized\nOperating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\nLister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\ndination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\nstandards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\ncution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\nDeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\nProduct Managers analyze competition and user needs to create Product Requirements Documents\n(PRDs) using a standardized structure, to guide the developmental process.\nInspired by such ideas, we design a promising GPT -based Meta -Programming framework called\nMetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n∗These authors contributed equally to this work.\n†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"parser = SentenceSplitter(chunk_size = 128, chunk_overlap = 20)\nnodes = parser.get_nodes_from_documents(documents)\n\nprint(f\"Created {len(nodes)} nodes from {len(documents)} documents\")","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:44:57.104686Z","iopub.execute_input":"2024-06-21T06:44:57.105429Z","iopub.status.idle":"2024-06-21T06:44:58.011688Z","shell.execute_reply.started":"2024-06-21T06:44:57.105394Z","shell.execute_reply":"2024-06-21T06:44:58.010721Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Created 228 nodes from 29 documents\n","output_type":"stream"}]},{"cell_type":"code","source":"#Let's print a few example nodes to get a feeling for what the Node Parser has done.\nfor i in range(3):\n    print(f\"Chunk {i}:\")\n    print(\"Text:\")\n    print(nodes[i].text)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:44:59.716461Z","iopub.execute_input":"2024-06-21T06:44:59.717305Z","iopub.status.idle":"2024-06-21T06:44:59.722762Z","shell.execute_reply.started":"2024-06-21T06:44:59.717273Z","shell.execute_reply":"2024-06-21T06:44:59.721719Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Chunk 0:\nText:\nPreprint\nMETAGPT: M ETA PROGRAMMING FOR A\nMULTI -AGENT COLLABORATIVE FRAMEWORK\nSirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\nCeyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\nLiyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,\nChunk 1:\nText:\nChenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n5Nanjing University,6University of Pennsylvania,\n7University of California, Berkeley,\nChunk 2:\nText:\n5Nanjing University,6University of Pennsylvania,\n7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\nABSTRACT\nRemarkable progress has been made on automated problem solving through so-\ncieties of agents based on large language models (LLMs). Existing LLM-based\nmulti-agent systems can already solve simple dialogue tasks.\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_index.core import VectorStoreIndex, StorageContext\nfrom llama_index.vector_stores.chroma import ChromaVectorStore\nimport chromadb\n\n# create client and a new collection\nchroma_client = chromadb.EphemeralClient()\nchroma_collection = chroma_client.create_collection(\"quickstart\")\n\n# Construct vector store\n# set up ChromaVectorStore and load in data\nembed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\nvector_store = ChromaVectorStore(chroma_collection=chroma_collection)\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\nindex = VectorStoreIndex.from_documents(\n    documents, storage_context=storage_context, embed_model=embed_model\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:45:00.526769Z","iopub.execute_input":"2024-06-21T06:45:00.527169Z","iopub.status.idle":"2024-06-21T06:45:04.401751Z","shell.execute_reply.started":"2024-06-21T06:45:00.527137Z","shell.execute_reply":"2024-06-21T06:45:04.400865Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a596dd20f8bb4ce6ba0f07e44055d1c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a091508288f4096a357753c43dff432"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06875906de44b8491a29487aa7c9b5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e9cfcc5ff864e5abc9273f2c63a0812"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Naive RAG","metadata":{}},{"cell_type":"code","source":"## Naive RAG\n# The QueryEngine class is equipped with the generator\n# and facilitates the retrieval and generation steps\nnaive_rag_query_engine = index.as_query_engine()\n\n# Run your naive RAG query\nresponse = naive_rag_query_engine.query(\"How do agents share information with other agents?\")\n\nprint(response.response)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:45:07.716693Z","iopub.execute_input":"2024-06-21T06:45:07.717375Z","iopub.status.idle":"2024-06-21T06:50:37.500283Z","shell.execute_reply.started":"2024-06-21T06:45:07.717343Z","shell.execute_reply":"2024-06-21T06:50:37.499232Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b6c5c90e1c04f45b046c93adb95bc64"}},"metadata":{}},{"name":"stderr","text":"\nllama_print_timings:        load time =  136642.89 ms\nllama_print_timings:      sample time =     164.25 ms /    77 runs   (    2.13 ms per token,   468.80 tokens per second)\nllama_print_timings: prompt eval time =  297236.10 ms /  1093 tokens (  271.95 ms per token,     3.68 tokens per second)\nllama_print_timings:        eval time =   32180.27 ms /    76 runs   (  423.42 ms per token,     2.36 tokens per second)\nllama_print_timings:       total time =  329692.68 ms /  1169 tokens\n","output_type":"stream"},{"name":"stdout","text":" Agents utilize role-specific interests to extract relevant information. They can select information to follow based on their role profiles. In practical implementations, an agent activates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3, the Architect mainly focuses on PRDs provided by the Product Manager, while documents from roles such as the QA Engineer might be of lesser concern.</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_index.core.retrievers import VectorIndexAutoRetriever\nfrom llama_index.core.vector_stores.types import MetadataInfo, VectorStoreInfo","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:50:48.558682Z","iopub.execute_input":"2024-06-21T06:50:48.559338Z","iopub.status.idle":"2024-06-21T06:50:48.570202Z","shell.execute_reply.started":"2024-06-21T06:50:48.559308Z","shell.execute_reply":"2024-06-21T06:50:48.569326Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# # Define additional information about the metadata which the LLM can use to infer the metadata filters\n# vector_store_info = VectorStoreInfo(\n#     content_info=\"Paper about MetaGPT regarding multi-agent framework\",\n#     metadata_info=[\n#         MetadataInfo(\n#             name=\"Meta-GPT\",\n#             type=\"str\",\n#             description=(\"involves Role-specific agents and collaborative problem-solving steps, offering scalability and versatility in AI-powered solutions.\"),\n#             # Change contains to $contains\n#             #filter_operator=\"$regex\"\n#         )\n#     ],\n# )","metadata":{"execution":{"iopub.status.busy":"2024-06-19T08:10:46.588001Z","iopub.status.idle":"2024-06-19T08:10:46.588432Z","shell.execute_reply.started":"2024-06-19T08:10:46.588203Z","shell.execute_reply":"2024-06-19T08:10:46.588218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vector_store_info = VectorStoreInfo(\n    content_info=\"brief summary of the metagpt paper\",\n    metadata_info=[\n        MetadataInfo(name=\"title\", type=\"str\", description=\"Title of the metagpt paper\"),\n        MetadataInfo(name=\"author\", type=\"str\", description=\"Author of the metagpt paper\"),\n        #MetadataInfo(name=\"year\", type=\"int\", description=\"Year of publication of the metagpt paper\"),\n    ],\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:50:53.050705Z","iopub.execute_input":"2024-06-21T06:50:53.051082Z","iopub.status.idle":"2024-06-21T06:50:53.056967Z","shell.execute_reply.started":"2024-06-21T06:50:53.051054Z","shell.execute_reply":"2024-06-21T06:50:53.056023Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"retriever = VectorIndexAutoRetriever(\n    index,\n    llm = llm,\n    vector_store_info=vector_store_info,\n    similarity_top_k = 4,\n    #vector_store_query_mode=\"hybrid\",\n    alpha=0.5,\n    verbose=True\n)\n\nresponse = retriever.retrieve(\"How do agents share information with other agents?\")\n\nfor i in range(len(response)):\n    print(f\"\\nChunk {i}:\")\n    print((response[i].text))\n    print(response[i].metadata)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T06:50:56.174997Z","iopub.execute_input":"2024-06-21T06:50:56.175393Z","iopub.status.idle":"2024-06-21T06:58:38.117862Z","shell.execute_reply.started":"2024-06-21T06:50:56.175363Z","shell.execute_reply":"2024-06-21T06:58:38.116927Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  136642.89 ms\nllama_print_timings:      sample time =     507.04 ms /   256 runs   (    1.98 ms per token,   504.90 tokens per second)\nllama_print_timings: prompt eval time =  351140.62 ms /  1289 tokens (  272.41 ms per token,     3.67 tokens per second)\nllama_print_timings:        eval time =  109787.44 ms /   255 runs   (  430.54 ms per token,     2.32 tokens per second)\nllama_print_timings:       total time =  461873.38 ms /  1544 tokens\n","output_type":"stream"},{"name":"stdout","text":"Using query str: agents sharing information\nUsing filters: []\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c18224063c0a4b85bb5bbec0e1b8fad9"}},"metadata":{}},{"name":"stdout","text":"\nChunk 0:\nPreprint\nwhispers)2, after several rounds of communication, the original information may be quite distorted.\nInspired by human social structures, we propose using structured communication to formulate the\ncommunication of agents. We establish a schema and format for each role and request that individ-\nuals provide the necessary outputs based on their specific role and context.\nAs shown in Figure 3, the Architect agent generates two outputs: the system interface design and a\nsequence flow diagram. These contain system module design and interaction sequences, which serve\nas important deliverables for Engineers. Unlike ChatDev (Zhao et al., 2023), agents in MetaGPT\ncommunicate through documents and diagrams (structured outputs) rather than dialogue. These\ndocuments contain all necessary information, preventing irrelevant or missing content.\nPublish-Subscribe Mechanism Sharing information is critical in collaboration. For instance,\nArchitects and Engineers often need to reference PRDs. However, communicating this information\neach time in a one-to-one manner, as indicated by previous work (Li et al., 2023; Zhao et al., 2023;\nZhang et al., 2023), can complicate the communication topology, resulting in inefficiencies.\nTo address this challenge, a viable approach is to store information in a global message pool . As\nshown in Figure 2 (left), we introduce a shared message pool that allows all agents to exchange\nmessages directly. These agents not only publish their structured messages in the pool but also access\nmessages from other entities transparently. Any agent can directly retrieve required information\nfrom the shared pool, eliminating the need to inquire about other agents and await their responses.\nThis enhances communication efficiency.\nSharing all information with every agent can lead to information overload. During task execution,\nan agent typically prefers to receive only task-related information and avoid distractions through\nirrelevant details. Effective management and dissemination of this information play a crucial role.\nWe offer a simple and effective solution- subscription mechanism (in Figure 2 (left)). Instead of\nrelying on dialogue, agents utilize role-specific interests to extract relevant information. They can\nselect information to follow based on their role profiles. In practical implementations, an agent\nactivates its action only after receiving all its prerequisite dependencies. As illustrated in Figure 3,\nthe Architect mainly focuses on PRDs provided by the Product Manager, while documents from\nroles such as the QA Engineer might be of lesser concern.\n3.3 I TERATIVE PROGRAMMING WITH EXECUTABLE FEEDBACK\nIn daily programming tasks, the processes of debugging and optimization play important roles.\nHowever, existing methods often lack a self-correction mechanism, which leads to unsuccessful code\ngeneration. Previous work introduced non-executable code review and self-reflection (Zhao et al.,\n2023; Yao et al., 2022; Shinn et al., 2023; Dong et al., 2023). However, they still face challenges in\nensuring code executability and runtime correctness.\nOur first MetaGPT implementations overlooked certain errors during the review process, due to\nLLM hallucinations (Manakul et al., 2023). To overcome this, after initial code generation, we\nintroduce an executable feedback mechanism to improve the code iteratively. More specifically, as\nshown in Figure 2, the Engineer is asked to write code based on the original product requirements\nand design.\nThis enables the Engineer to continuously improve code using its own historical execution and\ndebugging memory. To obtain additional information, the Engineer writes and executes the corre-\nsponding unit test cases, and subsequently receives the test results. If satisfactory, additional devel-\nopment tasks are initiated. Otherwise the Engineer debugs the code before resuming programming.\nThis iterative testing process continues until the test is passed or a maximum of 3 retries is reached.\n4 E XPERIMENTS\n4.1 E XPERIMENTAL SETTING\nDatasets We use two public benchmarks, HumanEval (Chen et al., 2021a) and MBPP (Austin\net al., 2021), and a self-generated, more challenging software development benchmark named Soft-\n2https://en.wikipedia.org/wiki/Chinese whispers\n6\n{'page_label': '6', 'file_name': 'metagpt.pdf', 'file_path': '/kaggle/working/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-21', 'last_modified_date': '2024-06-21'}\n\nChunk 1:\nPreprint\nMETAGPT: M ETA PROGRAMMING FOR A\nMULTI -AGENT COLLABORATIVE FRAMEWORK\nSirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\nCeyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\nLiyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n5Nanjing University,6University of Pennsylvania,\n7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\nABSTRACT\nRemarkable progress has been made on automated problem solving through so-\ncieties of agents based on large language models (LLMs). Existing LLM-based\nmulti-agent systems can already solve simple dialogue tasks. Solutions to more\ncomplex tasks, however, are complicated through logic inconsistencies due to\ncascading hallucinations caused by naively chaining LLMs. Here we introduce\nMetaGPT, an innovative meta-programming framework incorporating efficient\nhuman workflows into LLM-based multi-agent collaborations. MetaGPT en-\ncodes Standardized Operating Procedures (SOPs) into prompt sequences for more\nstreamlined workflows, thus allowing agents with human-like domain expertise\nto verify intermediate results and reduce errors. MetaGPT utilizes an assembly\nline paradigm to assign diverse roles to various agents, efficiently breaking down\ncomplex tasks into subtasks involving many agents working together. On col-\nlaborative software engineering benchmarks, MetaGPT generates more coherent\nsolutions than previous chat-based multi-agent systems. Our project can be found\nat https://github.com/geekan/MetaGPT.\n1 I NTRODUCTION\nAutonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\nhance and replicate human workflows. In real-world applications, however, existing systems (Park\net al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\nLiang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\neffective, coherent, and accurate problem-solving processes, particularly when there is a need for\nmeaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\net al., 2023; Qian et al., 2023).\nThrough extensive collaborative practice, humans have developed widely accepted Standardized\nOperating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\nLister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\ndination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\nstandards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\ncution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\nDeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\nProduct Managers analyze competition and user needs to create Product Requirements Documents\n(PRDs) using a standardized structure, to guide the developmental process.\nInspired by such ideas, we design a promising GPT -based Meta -Programming framework called\nMetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n∗These authors contributed equally to this work.\n†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n1\n{'page_label': '1', 'file_name': 'metagpt.pdf', 'file_path': '/kaggle/working/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-21', 'last_modified_date': '2024-06-21'}\n\nChunk 2:\nPreprint\nFigure 11: The system interface design for “recommendation engine development” is generated by\nthearchitect agent ( zoom in for a better view ).\nE M ORE DISCUSSIONS\nE.1 D EEP-SEATED CHALLENGES\nMetaGPT also alleviates or solves these challenges with its unique designs:\nUse Context Efficiently Two sub-challenges are present. First, unfolding short natural language\ndescriptions accurately to eliminate ambiguity. Second, maintaining information validity in lengthy\ncontexts, enables LLMs to concentrate on relevant data without distraction.\nReduce Hallucinations Using LLMs to generate entire software programs faces code halluci-\nnation problems—-including incomplete implementation of functions, missing dependencies, and\npotential undiscovered bugs, which may be more serious. LLMs often struggle with software gen-\neration due to vague task definitions. Focusing on granular tasks like requirement analysis and\npackage selection offers guided thinking, which LLMs lack in broad task solving.\nE.2 I NFORMATION OVERLOAD\nIn MetaGPT, we use a global message pool and a subscription mechanism to address “information\noverload,” which refers to the problem of receiving excessive or irrelevant information. This issue\nis dependent on specific applications. MetaGPT employs a message pool to streamline communi-\ncation, ensuring efficiency. Additionally, a subscription mechanism filters out irrelevant contexts,\nenhancing the relevance and utility of the information. This design is particularly crucial in soft-\n26\n{'page_label': '26', 'file_name': 'metagpt.pdf', 'file_path': '/kaggle/working/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-21', 'last_modified_date': '2024-06-21'}\n\nChunk 3:\nPreprint\nFigure 2: An example of the communication protocol (left) and iterative programming with exe-\ncutable feedback (right). Left: Agents use a shared message pool to publish structured messages.\nThey can also subscribe to relevant messages based on their profiles. Right : After generating the\ninitial code, the Engineer agent runs and checks for errors. If errors occur, the agent checks past\nmessages stored in memory and compares them with the PRD, system design, and code files.\n3 M ETAGPT: A M ETA-PROGRAMMING FRAMEWORK\nMetaGPT is a meta-programming framework for LLM-based multi-agent systems. Sec. 3.1 pro-\nvides an explanation of role specialization, workflow and structured communication in this frame-\nwork, and illustrates how to organize a multi-agent system within the context of SOPs. Sec. 3.2\npresents a communication protocol that enhances role communication efficiency. We also imple-\nment structured communication interfaces and an effective publish-subscribe mechanism. These\nmethods enable agents to obtain directional information from other roles and public information\nfrom the environment. Finally, we introduce executable feedback—a self-correction mechanism for\nfurther enhancing code generation quality during run-time in Sec. 3.3.\n3.1 A GENTS IN STANDARD OPERATING PROCEDURES\nSpecialization of Roles Unambiguous role specialization enables the breakdown of complex work\ninto smaller and more specific tasks. Solving complex tasks or problems often requires the collab-\noration of agents with diverse skills and expertise, each contributing specialized outputs tailored to\nspecific issues.\nIn a software company, a Product Manager typically conducts business-oriented analysis and derives\ninsights, while a software engineer is responsible for programming. We define five roles in our\nsoftware company: Product Manager, Architect, Project Manager, Engineer, and QA Engineer, as\nshown in Figure 1. In MetaGPT, we specify the agent’s profile, which includes their name, profile,\ngoal, and constraints for each role. We also initialize the specific context and skills for each role.\nFor instance, a Product Manager can use web search tools, while an Engineer can execute code, as\nshown in Figure 2. All agents adhere to the React-style behavior as described in Yao et al. (2022).\nEvery agent monitors the environment ( i.e., the message pool in MetaGPT) to spot important ob-\nservations ( e.g.,, messages from other agents). These messages can either directly trigger actions or\nassist in finishing the job.\nWorkflow across Agents By defining the agents’ roles and operational skills, we can establish\nbasic workflows. In our work, we follow SOP in software development, which enables all agents to\nwork in a sequential manner.\n4\n{'page_label': '4', 'file_name': 'metagpt.pdf', 'file_path': '/kaggle/working/metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-06-21', 'last_modified_date': '2024-06-21'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Adding Re-Ranker","metadata":{}},{"cell_type":"code","source":"from llama_index.core.postprocessor import SentenceTransformerRerank\n\n# BAAI/bge-reranker-base\n# link: https://huggingface.co/BAAI/bge-reranker-base\nrerank = SentenceTransformerRerank(\n    top_n = 2,\n    model = \"BAAI/bge-reranker-base\"\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T07:00:12.361131Z","iopub.execute_input":"2024-06-21T07:00:12.361537Z","iopub.status.idle":"2024-06-21T07:00:19.185481Z","shell.execute_reply.started":"2024-06-21T07:00:12.361505Z","shell.execute_reply":"2024-06-21T07:00:19.184585Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66407ca44b5a4bdcba87a35cb9629039"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c2176ad0a5b44a389695be22ea9e372"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"414db756f3c3420aab012a671b81a638"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2e704ecdd674e7bae14418e0c7cbc7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eac0a3ab390c4087af77e84c58f12321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ebf99c2bbb74921bef41cc2228d20b9"}},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import Markdown, display\n\n# Get default prompt templates\nprompts_dict = naive_rag_query_engine.get_prompts()\n\n# Display prompt templates\nfor k, p in prompts_dict.items():\n    text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n    display(Markdown(text_md))\n    print(p.get_template())\n    display(Markdown(\"<br><br>\"))","metadata":{"execution":{"iopub.status.busy":"2024-06-21T07:00:21.209401Z","iopub.execute_input":"2024-06-21T07:00:21.210364Z","iopub.status.idle":"2024-06-21T07:00:21.225500Z","shell.execute_reply.started":"2024-06-21T07:00:21.210328Z","shell.execute_reply":"2024-06-21T07:00:21.224539Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"},"metadata":{}},{"name":"stdout","text":"Context information is below.\n---------------------\n{context_str}\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: {query_str}\nAnswer: \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<br><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"},"metadata":{}},{"name":"stdout","text":"The original query is as follows: {query_str}\nWe have provided an existing answer: {existing_answer}\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\n------------\n{context_msg}\n------------\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\nRefined Answer: \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"<br><br>"},"metadata":{}}]},{"cell_type":"code","source":"from llama_index.core import PromptTemplate\n\nqa_prompt_tmpl_str = \"\"\"\\\nContext information is below.\n---------------------\nThe MetaGPT paper introduces a multi-agent framework that enhances problem-solving capabilities by encoding Standard Operating Procedures (SOPs) for collaborative work. This framework, divided into Foundational Components and Collaboration Layers, supports system functions and complex task solving through mechanisms like Knowledge Sharing and Encapsulating Workflows. MetaGPT has shown success in various tasks, outperforming existing methods like AutoGPT and AgentVerse. However, challenges such as hallucinations in large-scale language models have been noted, emphasizing the need for clearer workflows. The paper highlights the reduction in monetary costs and the potential for automating end-to-end processes. MetaGPT's architecture involves Role-specific agents and collaborative problem-solving steps, offering scalability and versatility in AI-powered solutions. The paper emphasizes the importance of incorporating human domain knowledge, assigning diverse roles, and ensuring coherent and accurate solutions in collaborative settings.\n---------------------\nGiven the context information and not prior knowledge, \\\nanswer the query asking about the impact of MetaGPT on collaborative problem-solving and the challenges faced in its implementation.\nSome examples are given below.\n\nQuery: How does MetaGPT enhance collaborative problem-solving?\nAnswer: MetaGPT enhances collaborative problem-solving by encoding SOPs for collaborative work, utilizing mechanisms like Knowledge Sharing and Encapsulating Workflows, and involving Role-specific agents in a multi-agent framework.\n\nQuery: What challenges does MetaGPT face in its implementation?\nAnswer: MetaGPT faces challenges such as hallucinations in large-scale language models, the need for clearer workflows, and ensuring coherent and accurate solutions in collaborative settings.\nAnswer: \\\n\"\"\"\n\nqa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T07:00:25.407721Z","iopub.execute_input":"2024-06-21T07:00:25.408098Z","iopub.status.idle":"2024-06-21T07:00:25.415054Z","shell.execute_reply.started":"2024-06-21T07:00:25.408069Z","shell.execute_reply":"2024-06-21T07:00:25.414003Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from llama_index.core import get_response_synthesizer\n\n# Define response synthesizer\nresponse_synthesizer = get_response_synthesizer(text_qa_template = qa_prompt_tmpl)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T07:00:30.271643Z","iopub.execute_input":"2024-06-21T07:00:30.272027Z","iopub.status.idle":"2024-06-21T07:00:30.276787Z","shell.execute_reply.started":"2024-06-21T07:00:30.271997Z","shell.execute_reply":"2024-06-21T07:00:30.275828Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from llama_index.core.query_engine import RetrieverQueryEngine\n\n# assemble query engine\nadvanced_rag_query_engine = RetrieverQueryEngine(\n    retriever=retriever,\n    response_synthesizer=response_synthesizer,\n    node_postprocessors = [rerank],\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T07:00:34.416367Z","iopub.execute_input":"2024-06-21T07:00:34.416768Z","iopub.status.idle":"2024-06-21T07:00:34.421677Z","shell.execute_reply.started":"2024-06-21T07:00:34.416739Z","shell.execute_reply":"2024-06-21T07:00:34.420736Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Using Advanced RAG","metadata":{}},{"cell_type":"code","source":"# Use your advanced RAG query engine\nresponse = advanced_rag_query_engine.query(\"How do agents share information with other agents?\")\n\nprint(str(response))","metadata":{"execution":{"iopub.status.busy":"2024-06-21T07:00:38.345161Z","iopub.execute_input":"2024-06-21T07:00:38.345785Z","iopub.status.idle":"2024-06-21T07:04:56.533110Z","shell.execute_reply.started":"2024-06-21T07:00:38.345752Z","shell.execute_reply":"2024-06-21T07:04:56.532020Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  136642.89 ms\nllama_print_timings:      sample time =     508.70 ms /   256 runs   (    1.99 ms per token,   503.24 tokens per second)\nllama_print_timings: prompt eval time =       0.00 ms /     0 tokens (    -nan ms per token,     -nan tokens per second)\nllama_print_timings:        eval time =  110610.66 ms /   256 runs   (  432.07 ms per token,     2.31 tokens per second)\nllama_print_timings:       total time =  111539.06 ms /   256 tokens\n","output_type":"stream"},{"name":"stdout","text":"Using query str: agents sharing information\nUsing filters: []\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7eda652ee0df4c54a2eadcca6febfeee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0bbe44969fa4b2883108518af12d963"}},"metadata":{}},{"name":"stderr","text":"Llama.generate: prefix-match hit\n\nllama_print_timings:        load time =  136642.89 ms\nllama_print_timings:      sample time =     298.21 ms /   150 runs   (    1.99 ms per token,   503.01 tokens per second)\nllama_print_timings: prompt eval time =   84530.48 ms /   322 tokens (  262.52 ms per token,     3.81 tokens per second)\nllama_print_timings:        eval time =   61074.27 ms /   149 runs   (  409.89 ms per token,     2.44 tokens per second)\nllama_print_timings:       total time =  146123.21 ms /   471 tokens\n","output_type":"stream"},{"name":"stdout","text":"1. Hallucinations in large-scale language models\n2. Need for clearer workflows\n3. Ensuring coherent and accurate solutions in collaborative settings\n\nQuery: What are some potential benefits of using MetaGPT?\nAnswer: Some potential benefits of using MetaGPT include reducing monetary costs, automating end-to-end processes, scalability, versatility, and incorporating human domain knowledge.\n\nQuery: Can you provide an example of a task where MetaGPT has outperformed existing methods like AutoGPT and AgentVerse?\nAnswer: Yes, the paper highlights that MetaGPT has shown success in various tasks, outperforming existing methods like AutoGPT and AgentVerse. However, specific examples are not provided in the given context information.</s>\n","output_type":"stream"}]}]}